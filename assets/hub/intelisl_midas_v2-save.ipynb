{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "partial-trout",
      "metadata": {
        "id": "partial-trout"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# MiDaS\n",
        "\n",
        "*Author: Intel ISL*\n",
        "\n",
        "**MiDaS models for computing relative depth from a single image.**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/midas_samples.png\" alt=\"alt\" width=\"50%\"/>\n",
        "\n",
        "\n",
        "### Model Description\n",
        "\n",
        "[MiDaS](https://arxiv.org/abs/1907.01341) computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using\n",
        "multi-objective optimization to ensure high quality on a wide range of inputs.\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "MiDaS depends on [timm](https://github.com/rwightman/pytorch-image-models). Install with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "experimental-clinton",
      "metadata": {
        "attributes": {
          "classes": [
            "shell"
          ],
          "id": ""
        },
        "id": "experimental-clinton",
        "outputId": "aecbf32b-6d05-41ce-aaad-d5133bb439e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecological-distinction",
      "metadata": {
        "id": "ecological-distinction"
      },
      "source": [
        "### Example Usage\n",
        "\n",
        "Download an image from the PyTorch homepage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "responsible-qualification",
      "metadata": {
        "id": "responsible-qualification"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename = (\"/content/SH07.BGplate._depthExxtraction.jpg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "empty-policy",
      "metadata": {
        "id": "empty-policy"
      },
      "source": [
        "Load a model (see [https://github.com/intel-isl/MiDaS/#Accuracy](https://github.com/intel-isl/MiDaS/#Accuracy) for an overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "announced-structure",
      "metadata": {
        "id": "announced-structure",
        "outputId": "156612c2-854c-46a3-83a3-48a82f97a56d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floral-breathing",
      "metadata": {
        "id": "floral-breathing"
      },
      "source": [
        "Move model to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "decent-candy",
      "metadata": {
        "id": "decent-candy",
        "outputId": "97371124-885c-4a84-e16c-5eaeea13f368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (pre_logits): Identity()\n",
              "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "informed-china",
      "metadata": {
        "id": "informed-china"
      },
      "source": [
        "Load transforms to resize and normalize the image for large or small model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "developed-strip",
      "metadata": {
        "id": "developed-strip",
        "outputId": "63f681d0-9f8d-4348-e6a4-df6ae94ac757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "visible-circuit",
      "metadata": {
        "id": "visible-circuit"
      },
      "source": [
        "Load image and apply transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "outside-establishment",
      "metadata": {
        "id": "outside-establishment"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(filename)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "input_batch = transform(img).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "arranged-telling",
      "metadata": {
        "id": "arranged-telling"
      },
      "source": [
        "Predict and resize to original resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "horizontal-engagement",
      "metadata": {
        "id": "horizontal-engagement",
        "outputId": "09f883f7-2276-42b3-e857-d96ff1746a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    prediction = midas(input_batch)\n",
        "\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "output = prediction.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "proud-tomorrow",
      "metadata": {
        "id": "proud-tomorrow"
      },
      "source": [
        "Show result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ahead-empty",
      "metadata": {
        "id": "ahead-empty",
        "outputId": "c1d1a4ab-0892-47f8-9317-8aebd9dc84bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADKCAYAAAAGnJP4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbzklEQVR4nO2dW5bjuq2GKbsrJyPLHDK4zCPDyntS1nnYpW5Z5gV3AhS+tbKSdFkiCJI/IZCitn3fS5IkSWLDY7YBSZIkdyJFN0mSxJAU3SRJEkNSdJMkSQxJ0U2SJDHkV++P//jbP2NsbdgU5479pXfvUsr+Grh4f5Wyyg6TbUP+fn5MsD2QNgPotjmkv0H7Q8vfA7+26ry/dt54QNq9/foq25PYBx7I6yB9s3LPrXHdv//zr+YN5/dqb+wvdaE9ozGoPwvZ3jvV8f+v/64NZvJwILhTsKi3Yf/+UyYhcNhfxWxLq2Q5gzEdv2dLd9LtYT7gt8emJ741sZ1Jr3Mfvr+r4JYyRxA/TKi30fbYaG2DFbSf3w+fAoPSTS+EoNdJrx3EQYdusb/2sj22947GsXe2uCY6YARs39v9YH/BBPT8G0p/5EaQr72Up9HToBFdr++v/e0/4ThSBcYpAyoiPvYQzfbwbJsHpKP8nuh1xoR4tIvh6COW49Zw3QQV6V4bwiQfeRM+otwDVB4020MSVv8+hIkiGttDVmxGEe9RJsYuqI2UPvljyyHw+743F6zEGN0fuzDXgZVeOItECrAwmEEXRWyj2FkE+3NFnJoT7PW6hi2oJyKAqKLquj3K9jjq86za0rxfywYP2tGbmIQRy+kezk/xpUFKLUh0EsvtaIYdm4pK/20IL+r68/99YgpH/RjGeULo3X6mFrxeotGpJOILaRn9GuBcuEgo5gnN+6FUXSLv4hD2uUmKwQjV3Quj6C1F+S+aflrlpYgD4mZ9VBEe+lRtZwA4BxpYaM8cfVqwPVYR3qlbxo5tUsmF7ja4gP7q2dwQGVDe8/TbqUCFchVBxVBrw1p7vXb5dITTFMP0fbopvB2BsRDYbdOLqEf2dwT3/N+oxRoN7iiWmrQm09Eku4hOTBfdUnIRTp3RBnesuB8iTRTV+k/b95rSL1JodSFtiSMsCmKi3d5Cr2DU7EJ0D+4a9bJfisAIBGYPaOu+pK2Xwdr16qNoIiy5zzda3Z3jSnRLyagXBHcQGA6iZdrxLGIa/vP8xiT0lWEtuC+LKOZ2KYt77kT34NZbzxaKLJZsR6wAcN5O84BkfySd3/BzjcU5DAZ7yd2K7pm7ph1Wg/sUU7u+e0YA4O8mRBVbaVgHODGF33InwyBdGEJ0S1lXeEMeJETlZ9Dt342/AwcW12cr9iMX9NIQ3Inn594r7NUNI7qlrCu8SyARzRnkDrP/KKEdzUv0C2i0q5xiCCW6peRJZy5x+Ph8qycIT8xedAtAeO+EPetXA8z5wVJC6VBwE2E8tfECYx0W6WLO3JxERsAFv183SSBI9BXpM4KpQFIMU3cvXJ2kvVdREEr0e0uhvhm5LkAAmzJQTjFEX0yjeybQZ3CgZJoiSZC0NEBaFxbSGZnpaCGHpPAicf7EkzhhIY3gIjdiFop6U3jj00shZPsaIf00vIi+yIcpizgmSZIBM8b6AvqidApE/Kg3t6IliVO0x6XyF1t0X46ont0aKweYq91rku3KJHhQNRN7BQy46yFkxBvIv0liymvu2JgbdgYS31DCe/hUw7dB2itJvOLjWT/IQHYrvOfJK4gvPeC2PZOl8SG6paRYJEkyJtiaUA1fp4wFOKHI5QKMpc+ct88BNIp12Z5MXH7ySvic3civAvsbQQHyvC4fS537zDMu21MAF9set0d/oj7+Pvrd8dsF8BXpnrmebObspDNXEdIqgjuxbV21J4JpdvdODeO0o5PxXUXokz9+Rfegd9LZFeMGq0URmAEgFoXM7KirCH5gXE0YnkUTg+LXI/yLLgaNmRdtQj2fdv0qrtpj3xGBWNVZ8pzUADl9T2Dy1qUY5HgjtZ3ghyqx+eW1RLfFVRQMOsc5+rgODvU8W6TOf2ai3W4iRSDYT9ur1M96gl+Ee4juFaPD2KcvYnjk7O9MTZCoTeIjUVWLdi0FV9p2y8+yn7in6J7JmZoP1X+O/O4qLzqgaudpwXlYj5Hflf3QehTflQ+aEUFAqFN0S3G3MyLhURMd7OP4zw+Pi9t/g3CUd9igKmrPsPtXD7uh4nv8jlXfnogiFtMwed0U3YREK18NuUaFgQhuT+T93mzFXgy5Zx/IAA4RGSKh1CnaixJw0W05I1Blh2Sq4TdQgVQT0pu3A0dQo4lQKfwJJFKdx6I7cobifraET5Q85W+8iO1rV89taiLy6G2AZLR+vheq3tg8LTOvO/gEO9AhKwlv8Gg3nMieCex3r9REbYYQr5gKoSKX003hNSW0uNZw7u+VuEbBI2Hm/H2W2M5IN0DLlF1IOxy8gvgGEN5lSD9PoSeII7Hk/t0Cr3lepQ9T7uofd7s74V+8gJ4sNZPoPk74IHUMMtkof5gyeOTrPNol7T21wrHfUARfUEuUYCym2YyMyJGv81dVt8fmT3CTxAkz0hyjMo3PQkzhlSLFNkliMuET7Cm8XFJskwSOh0W9M3MSb86ckCRJYsXE76MEFF4n0W6InQtOfCVCBH8nXYbR7ovQXynXlNkfpjwW2CIttK0kJtoE+MgomBTeRAhf+3pSeBEmBPFVKS78lSRe8CW6pcQR3uR+RJroErf4E90oOIjeQkW7STIZL7sYfIquE+cMSeFNkgSJT9EtJYUXZUIAX62yqBbB14kswlrkV3RLwe1sqP3GaneEAzEJIbyluPAVmyi+Tj7wkGKI84208+E5LcdBvnJx3EMaBx+3VPvMtjQOfMUmD8JJiMTr9RIzlXbUu0I0Z0H6KvEE8WUHLPFEVwrtx4wUFDgR/ZRRblhmpxjuK7ql2CzWpfiOiZxmSBIk2dutSOGtk4KbRMX1IeaJKWF2MkQV3Ewt3AvhhfegvT4omWr4Q1TBTdaFGLmiizEpxTMzkup3F94U3CQ6DIHO3l/KnKMl7yq8KbjJ4ow++54jYCaKwhsmrxuNzOfeC4UXqVJ0z2SqIUmSEYPUgq+vAUdgIeF1Ge1GnmScRbnbtg0fZRN/xDl7wZJ91zmfoVvmSyXfub92X2cxRM3pOvLhVWh7wjv77avkkxTdFjOEVwl3whuJyX7jRrKY61OgbUjR7WEtvErRbkJkouDOSBtcy0wRriCwlzdH+AjrrxWvnt+NnNO9GUfOOPPGsqToYgg+86fwIsh0zBspvHJkegHLQrneJMFQE96IKQjwBKI0zlN0vaGQ081FNCTpLzAQAfMkzE17jc5dKCVF95NZUayg2LoVWU+LhA58dJdH9nM9ZwmwJ1/fW3RnN4SACE0XWEshDb59Kxn7UFKUwe1Vi3Jr1wpFw33RPRd8dYZEB7SY9bQGiqHY3EpYzxDqHU4YewNZ65td1zKNvg0Gwbz9DNMKB/BIV8MZVg4+i8Z55dzT4+4PywmsYn2mCKzlILUqa1SOI1EWYVRfxSi3lGGkiyjIsZhtj+3PdimCbdOFUBKNtlH2z7TodUIU5BJLP0gKPNZuo37WFV2c2DyZplQNkLuVgnm3xZPIUgThOrBTXP0wqy16fU7Ypn6k+7RXqnA5OSecFyC2bVNdJTZrI60BeGeRpbadVn/qrRtpoTipQ8ZGP9L95WBzg5cBckRHXuw583qVa1Pn1JWAsOrP56eLGYuHLYj15wQefdH9ciC6NTTykqNXU58GnfOoF/Y1WQvbPOLlteYVkUohHW0EfWqe8HQNQjClJpteCJ0a8CRcGpMKQKCw7Tf7TSOn47PJa5++19gcbhvNnlgV2qsvuhPTCx5yu55eX0wUsRrYXub1WcJP8bMXn7Ug+HKwe6FTY4+5TWHmy74A2BxZrV1r9zh+t8IeTs2u3Jq4a0FF7QWk8785CERYWEmGVLA05cAbaqS72iPU7EccDhKTo9fJN59E+HgXcu9tTPDfIKf7IN94KTC6gukk50gG6mPvnTAiq/n07uMVwqjNFX3YFd39100W0lYbdM7ZIj85JCB2hafdVfpNP9J9ZKQ7JAUbza6Rkch2wBNsXKv3G6Mc+iCny9jvQTE4B44u6d82i0RRb6y2trII/fRCdwFF2pRS3O8XWGCh3iObh8nAw2Ycjb3UDPZgkXAN7b51+Ohczshvg0jXQ090BMcdHoTFKTtlsl3Sn8Yit4CojiD1LeVy+pHuM1CjSHYglQHt3Jc3jOKpUdA5knERpVdwE6XOiNuc9+WB6N410lU8eNvnGPXxeH3GQMwkoiCrSMoEL0LNxVtfvrCW6HL6jJEYztRcr1FZHWJjrrggJoGDRTXt6DtK/x5sGcM5aZ/fri7wGs2aRGWzO74DcWkSMWsVKPoV69+jF5awLzRdGLwcEcfhnjCVHXf5K4U+M1vIVyaQqNox8gnPZ4MtY/Sbu0nkK+LicUY6A+SgSp/Q+pKL9pmI+RiMOuQluwnAB13RfUXavTABq0UUr+kKEoZ1WWGRa9v3FM/F0N0ytkq0Ozli0iw9nKDfbKFMdOKYmO/2uN6j1fdHdV1nn64qhn4w1hRuceai7XmhrIbFBx0N8CiaXGZN32o53VJK/MeUxYIqjRyniouW8rvjQTDRNOuUiWV+n/Ua8O70u5TLYbZHmNfRN3c7JRosJdoEjMVU5fQvYTzl93Uj3fL5WLLtfh9VwuU3ryjbzx1cd99N4J077DjywEB0f/5b8lgDuVuJc/sFK23RZkQbIfznnKnBThQ9x/QzYp3mbhmb0RCTBq9EsW6Fx+ScBF3c+raDuohm5KsCKNJ9I9uhjXqkSEdXVBidwonYOTHDHkfjeWYkzhkfWLsHW8bohmgAyTmFzBsamOxXsAXwbt8srBfUHAk4FssuRF5I8+pgrVVKt8LjVLBDTn5aHK5wOmbO5GIaA6DrBjldCUvWINxLBBAUbZKa/Fz6LTC5mDYffE63R1Snuo0Wxc2QwfT8BBnOvqwJj1tfd9BfSFO+/4JA2mRwni7uZndEc7Cibx1BOJzuHongOnG8jWlv9pypdRCdLWO0m6LQcLTTSMxlNOXRpg4ufegQ8yDJs2AawzvwZvRG2kqOdphicLsYNdEs66KvIr/0E9/KdVMEu/gISi8s3dEYaEddqMUop/o8xLndzs3D4WEce7BBGVaky04veHKwwujJ1MJ8XPrVCNVgyNPYDQCmLcALadgbR0XtYGPzCxVxZJMjU+IRYTxvJdQ+ZwjzF9Kcgc+7qpiBx4sdTNz4cwFyT64tUH+jIl1OQZ6QHNigW3kUEo82lbivK0ccBx+sUAcMk+oLfjliiU71w2hsuoq2HNniyi8VnJvnAhfj2IMNSrBfjtA8Eb5n3Pmg8xkDfeg4S5scdVCLansXds+4ENQ7InrKWEt0lRt3b/xvtUIil4EggqCJCYf6AbzK9zdgCZH2WAfeyxHjGyyJI3Eyzz+rXJxMxWgMLyHiVKS2jLHO03WZF+BjXa1ucasK4ar1KuV9cFLrqdXNbyKa+gcF9Rt2EOleLnbfKIheTOzwoRbhSrll+AFtg7NrRqeQLYOTDtry/fVvoZDYMubtyxFWsD7dYX6h4o19jE80FLODVrWOhGgZCp9330tPAvx9ukKGSCHhn2adPFTWgw3KOAnGSFAHKKTO4hFg1IjywJn90G7bj3TPlXJWwRbg8Uo6VVzwXlRucPBbYM0lo11nc5+u0BFHaJynuz+Vm8rTftjfZcb+xhqpmDuq3Iowu27YXCoG7YGo9nKE98ZR2BvFbSt/uV6H7FucFS21k5EMviU02a2em5XEyp9glwTbj91v3fJgA5trJZaoFBLBOlPFbTVRBCI2GXC2jJXrlrFmIVBrBNGKPDXGubOpPfJCVfIHdreK1BF8DaF3JCPd8ihlj9QwFzZpsZuRI5h8+LoLTA59MChjJpT6re4TJGAtZL0GrL2Qpsw+Gq1S1XPgJvEJJgkJKUiK2HUi2vxDP9I9GjBCBSW3gJWCe3Zz4J/hBPN5QcKB2uasA4MZ10oQ+KlXnF5bcCLdEjzSfQMdCTbqPmUbm8I9Zw/gu2Ll90wnvONgq9gB/I00T7Mc6VFaUURnuibTCveFMyY9i38UGv4ffZG9K7rb80W2R5eWgMq18C4ixhY9zihvfUesBKPVRkZbmKqXrCyWLbiBpcSBN9uMU8aUDn3dkQLY/DXKPs6uhTv2+oRFgEW0zdMTswS1d1l4ka5jB6FFtF4XdkQ74XQw7ASSrAVLuAhd55ZR7xWAz6Fu6oruw/Os1LENI0qtDsWuuaIwtiaQ30U7bjbPLCUuxLEb3QVTIulLmaxI9+Eop4sSUoGotloaahsZrDCNqFVSPI5aRB+Mq8KLeonCfOPO0PM31C990YW+BmxCS0h5PQAXFb7/WEIwR1Hrn7LYRZG48fhqghEdyXbjih1GoO8krNzoGHs9SHS1Q3aeeH3aJtHRYTbpTARYMp1AY0VhoY5VzTF+Jz9D/NgV3efDKL0AMJS93sV8OQJ3fS/fjDRDAOlJwOsK9FFPr/ZJwxEzqI/u4ssaGPdi1r9IontuiJkr6aiyK055Ma636ooy/r3LwNGM1vD3lhwb5AgW+XvPi+eHD/Z9czEZ1Gx4cA8x/wVaSJOrPDcaPXgBTWqd0U4dLCoT0KBzoSaO5Dcm4mIoDBZpBYig2GAvuCM/qUe6M8AIWu3sdZw4UVMLbcdDJwIs0hMHFA+Rxl2hih+0zTxHuz1m9Mmar0bN0xfdbRdvAHJkVrEDYxlfiE/lEq7DfoSDH8HGHDiekOr73LaE2sERHUxd3QS8E+j5CerDruh+Pb9xFgGAiA83SoN28mfDScPrDfK7Iz9lWoGOdSSn9dUrSg+A1j1qtFsKfPKRWni9+mrku35Ot5JeeFwk5mU474HFlHHt9XrOBKApjOcJw1qAIw/I6EB8TxURr+3q0a6rDpYC93s/0n2MI13OLI4Vi2fl52BRrPyMMmFQxZtzH045EO621WqE9iCHtj3EDqqtNdGocec+QX0qEI90reCIEjUihlx3FX5yJAy8zPJJ4i5ABUcNgSaVXE2XuG4Gs22t9aPHNtbMvuhu3z83wleOHck1Ln/trfX6/rXaUS3nmh6tKHZ2Tnd2h59Fq97a7THyt3bECxGTVcE+cbAi3b8pLKS1gHfaz8andvjxgtn19zTB/329YtSqMejvKKzkKNh4DsSIIKYdo7b5DLvrkS7zNeBflrNbM7IF9GazyPbdH5JCp/VkMIuj882OyK9EFZUDiS1LH9chJppRGZLt7a2tehPdeWF75M+u6P7f439Is+BIRH3fpMf/TrRaE+9eGROi2tki5m0gaCKV+6X2hVH52LaARsetrZQRsM7Xfy6icXO6gN0Lmowe539hRbKUUi5OwQ4IitC/lQdJUfT4SHnoiPBdxDVarrIniFTBga/Sw3zF7uPI8qyA+n5kd3/L2PZiVZwvMPWytYWyZzdJ6M8I1ckb03cEKIOZhKQnwn5KATc+IVEsuy0niyVlcqDq3LVtnpU1pyuD9MJ/SYb8ZsNHyt/N0wT69Dp6XSh7aQZeNHyGGxlfkYoiKHiLPKSJ8lg9Tjvg2gkzoUBEhTqGqeWRIehTy1fnfx/ZDN6nC6081+G/GuVgdxoMrzk5HGszJpJBC/4IwQmhx2qRq+SEcR14Fnn2njBShEnzxYvWGLak55PWeJfw45Ob0/07IdL9KrjZ4xsqQKT8baW8isNrnQS7gIZLMXz6SDI6mIVqVGIESWgQTQ/pJ9KCCG0Xr3l8iJBhwGrUmVYwcraRtXvh6yIOvZtRI65rGTWawtzaZtax5epw6L0pAl8KXEwh0cHsnQsHXgcnhOkTA6MJIX7HCtRIIKQFzwLoU9qhE9SnuqtvoE9TujndAdDH7JowgyPko6xGb7/eGyPwkImmNati7W/aoCjEmuLqdTBrpFW0toxRfBhJZD2tITw7frva2fttKchI93rTb24+cRDl9kS5KsQIe1r3Botw7Z6I8kcRPiftMgtPA7ZH5Hw1xscY0cKIindGoifFp9gKRLp/3/qR7heoiE/A+cuGMDUFs1pWQ5Uu94aKcPeeDSgLZz1RJkXJgoQRV+x2KuHByg5KCswmiiiO7jtTaKengC6Mnviu9o7GBynS5dJLZIME+WTX6PH6LMTdewNF+POekNeUcZPHiFa7SAzyM7MiBiu060cNSkZQ/QURM6zAeKUnfK2gBZ8Pv4rtX75jbRn72v7H2rtI2aNa66ivrlhey+yJ5SV1ABThnrBf7UXtQgBMahhh1hrkGLw+ilqt4Ht4QxArjD2xuQrLDKT3T3OCyZpvRXO6lC1jZ76gZ8YOhQUulvVFt8Yi2tWO1n21hB1CM0rOMxh6QIVHPFXSaRZoWghqE1UQRyKGFW2vE20pnwI4ehrEPv28bxV7ffxbjf7RjkrphQ+QuxM+hW2QYgAf0QgTzM/FNngkfKUbxfdwtIBGZUYUBY2aMMIDnVgl0nWagtgTHG95fGrf4T4Ntvxw9t3INtZCGgesUJbSFmJwxHpwfhsNKO49e+GiXmOwiyHQSxNe830Q4eHkd5vbAo0W0n7/lpmT5N6ve69AO0Ywgn72EbSOw5yuFtWdBgOxOkcKfWGFR8JXwRQRdqCoQ6gNaOkFMwxRBg9EMLQjbc0cO1UQh7sWZqVlBNHuo7VJ/BxwiO3TpUQx2Cit9vgFTQX89S+w3G0pHXG97mJo1gEm7JC8NlaYPSyYUZk5WEHbrxhCTE4VAcDahfFzbh9rlY3frge5RjW9AH3HuX/iF09c//r95/3hAg8rnxK592x5s8tpisHDyvaIkfjIRkWw/l7rP1Q7aHt0dXziZUFNM9Jt3fv9lDHON9Kq2yMUzhXt7akDClz/98B9skCBr7+EARP2oQ1V5h4mL8loYEL8oblPlTtgIakfypMK1i6xBTTDdJKXHTGYOl/fboQs1PbPXuCutmJOX0JHr7jfVyeASse83hdaPljYP2wAHPjjcKuC2mAU3jEzEh/pelinfij294+JBH5FwlluX/ss5HEu/GxL/16DLWPzHheGuxvOvyV8vBIi8t0FuPO9usdAjoV9BHbiORNl4UsKWB4OcFoXwm+WkyJJZAHX9ERrRh+anVAbCefB1c4n4JpBpAsrmMJIzr8qDf3daPuv0RdKgTZBotyqwCOPmBxFQ9BB7GlBzbO4j0/W4tneTXcRXmKh2gOPUntlk4oe3tcKiOiR7rv1HfMW6Q7G7yDSbV/ccjA3Nv7e2x2nuneXUdbVVojQ1wQeW2dMFP/HDvpoiPIZGkkwj4PNe4B2nvT/PgoIOFCjsY/7DMuZk96q2f3q/E2KkWieeVx8A7l2EOnqzl2visB+dRr4uzKQMNEeOOI92dXa8gUV+1qZNXF/L79yjVPh5ERGVnBFp0dvSyA3O42xCyqM3SgXmSa5Cs5ssPZDeADk/er70TX9fbqVZoc0bi9afeMjz9qXxfquAe4BJWPhH4k9OtId+OfjhQ3k/a9oPXJ5BfMoWL0e+7XpRh/UTv9A7OwJY+96iNhIMyuiPoOp94Mo8tsOFcgkSZKEjYfcd5IkyW1I0U2SJDEkRTdJksSQFN0kSRJDUnSTJEkMSdFNkiQx5P8B3z1OgcNR6bEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(output)\n",
        "# plt.show()\n",
        "fig = plt.imshow(output)\n",
        "plt.axis('off')\n",
        "fig.axes.get_xaxis().set_visible(False)\n",
        "fig.axes.get_yaxis().set_visible(False)\n",
        "plt.savefig('depthmap.png', bbox_inches='tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "south-lodging",
      "metadata": {
        "id": "south-lodging"
      },
      "source": [
        "### References\n",
        "[Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer](https://arxiv.org/abs/1907.01341)\n",
        "\n",
        "[Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)\n",
        "\n",
        "Please cite our papers if you use our models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "continuing-assessment",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "continuing-assessment",
        "outputId": "805c9218-a01b-4ab1-da9b-b27493b3265b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-23ca58b53b1e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    @article{Ranftl2020,\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "@article{Ranftl2020,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},\n",
        "\ttitle     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},\n",
        "\tjournal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n",
        "\tyear      = {2020},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thousand-editor",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "thousand-editor"
      },
      "outputs": [],
      "source": [
        "@article{Ranftl2021,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Alexey Bochkovskiy and Vladlen Koltun},\n",
        "\ttitle     = {Vision Transformers for Dense Prediction},\n",
        "\tjournal   = {ArXiv preprint},\n",
        "\tyear      = {2021},\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intelisl_midas_v2.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}